Modify the tokenize() function:
Use an if statement to check whether clean is True. If so:
Clean text_string using clean_text, and assign the returned string to a variable.
Tokenize the new string variable using the split() method, and assign the returned list to another new variable.
Return this list.
Outside the if statement, write the code we want executed if clean is False:
Tokenize text_string using the split() method, and assign the returned list to a new variable.
Return this list.
Outside the tokenize() function:
Use the tokenize() function to clean and tokenize story_string, and assign the result to tokenized_story.
Use the tokenize() function to tokenize vocabulary, and assign the result to tokenized_vocabulary.
Finally, loop over each element in tokenized_story and check whether it exists in tokenized_vocabulary. If it doesn't, add it to misspelled_words.

# Default code
def tokenize(text_string, special_characters, clean=False):
    cleaned_story = clean_text(text_string, special_characters)
    story_tokens = cleaned_story.split(" ")
    return(story_tokens)

tokenized_story = []
tokenized_vocabulary = []
misspelled_words = []

# Answer code
def tokenize(text_string, special_characters, clean=False):
    # If `clean` is `True`.
    if clean:
        cleaned_story = clean_text(text_string, special_characters)
        story_tokens = cleaned_story.split(" ")
        return(story_tokens)
    # If `clean` not equal to `True`, no cleaning.
    story_tokens = text_string.split(" ")
    return(story_tokens)

clean_chars = [",", ".", "'", ";", "\n"]
tokenized_story = tokenize(story_string, clean_chars, True)
tokenized_vocabulary = tokenize(vocabulary, clean_chars)

for ts in tokenized_story:
    if ts not in tokenized_vocabulary:
        misspelled_words.append(ts)
